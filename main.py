# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6H_FA8lcs7zV6c5_m6_WhwXRYOOT76U
"""

import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))

!pip install kaggle

import os

os.environ['KAGGLE_USERNAME'] = "fjgjajdagj"
os.environ['KAGGLE_KEY'] = "KGAT_7fa458b4f9fbae54289c4032cd01498d"

!pip install kaggle

!kaggle datasets download -d sumn2u/garbage-classification-v2

!unzip garbage-classification-v2.zip -d GarbageDatasetV2

import os
os.listdir("GarbageDatasetV2")

import os

base_path = "GarbageDatasetV2/standardized_256"
print(os.listdir(base_path))

import os
import shutil
import random

source_dir = "GarbageDatasetV2/standardized_256"
base_dir = "Garbage_3Class"

mapping = {
    "biological": "biodegradable",
    "metal": "recyclable",
    "glass": "recyclable",
    "paper": "recyclable",
    "cardboard": "recyclable",
    "plastic": "recyclable",
    "battery": "hazardous",
    "trash": "hazardous",
    "clothes": "hazardous",
    "shoes": "hazardous"
}

for category, target_class in mapping.items():
    category_path = os.path.join(source_dir, category)
    images = os.listdir(category_path)
    random.shuffle(images)

    train_split = int(0.7 * len(images))
    val_split = int(0.85 * len(images))

    for i, image in enumerate(images):
        if i < train_split:
            split = "train"
        elif i < val_split:
            split = "val"
        else:
            continue

        dest_folder = os.path.join(base_dir, split, target_class)
        os.makedirs(dest_folder, exist_ok=True)

        shutil.copy(
            os.path.join(category_path, image),
            os.path.join(dest_folder, image)
        )

print("Dataset prepared successfully.")

os.listdir("Garbage_3Class/train")

import os

def count_images(folder):
    total = 0
    for sub in os.listdir(folder):
        total += len(os.listdir(os.path.join(folder, sub)))
    return total

print("Train images:", count_images("Garbage_3Class/train"))
print("Val images:", count_images("Garbage_3Class/val"))

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 224
BATCH_SIZE = 32

train_dir = "Garbage_3Class/train"
val_dir = "Garbage_3Class/val"

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

base_model = MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)

base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(3, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10
)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Get predictions
val_generator.reset()
preds = model.predict(val_generator)
pred_classes = np.argmax(preds, axis=1)
true_classes = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

# Confusion matrix
cm = confusion_matrix(true_classes, pred_classes)

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

print(classification_report(true_classes, pred_classes, target_names=class_labels))

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Now evaluate properly
val_loss, val_acc = model.evaluate(val_generator)
print("Validation Accuracy:", val_acc)

# Predictions
preds = model.predict(val_generator)
pred_classes = preds.argmax(axis=1)
true_classes = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

cm = confusion_matrix(true_classes, pred_classes)

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d',
            xticklabels=class_labels,
            yticklabels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix (Corrected)")
plt.show()

print(classification_report(true_classes, pred_classes, target_names=class_labels))

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

class_names = ['biodegradable', 'hazardous', 'recyclable']

def predict_image(img_path):
    img = image.load_img(img_path, target_size=(224,224))
    img_array = image.img_to_array(img)/255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)
    predicted_class = class_names[np.argmax(prediction)]
    confidence = np.max(prediction)

    plt.imshow(img)
    plt.axis("off")
    plt.title(f"{predicted_class} ({confidence*100:.2f}%)")
    plt.show()

    print("Raw probabilities:", prediction)

for img_name in uploaded.keys():
    predict_image(img_name)